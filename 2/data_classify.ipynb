{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms,models\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from collections import OrderedDict\n",
    "\n",
    "from XJ_DLClass import RunBuilder\n",
    "from XJ_DLClass import RunManager\n",
    "#查准确率\n",
    "def get_correct(preds,lab):\n",
    "    return preds.argmax(1).eq(lab).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 数据集预处理 #"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "datasets_trans = transforms.Compose([\n",
    "                transforms.ToTensor()\n",
    "                ,transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])\n",
    "])\n",
    "train_datasets = torchvision.datasets.ImageFolder('../datasets/data_classify/train'\n",
    "                                            ,datasets_trans\n",
    "                                            )\n",
    "test_datasets = torchvision.datasets.ImageFolder('../datasets/data_classify/test'\n",
    "                                            ,datasets_trans\n",
    "                                            )\n",
    "train_dataloader = torch.utils.data.DataLoader(test_datasets\n",
    "                                          ,batch_size=10\n",
    "\n",
    "        )\n",
    "test_dataloader = torch.utils.data.DataLoader(test_datasets\n",
    "                                          ,batch_size=10\n",
    "                                          ,drop_last=True\n",
    "\n",
    "        )\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 微调ResNet50 #"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\python3\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "D:\\python3\\venv\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "class ResNet50(nn.Module):\n",
    "    def __init__(self, num_classes=5):\n",
    "        super(ResNet50, self).__init__()\n",
    "        self.resnet50 = models.resnet50(pretrained=True)\n",
    "        in_features = self.resnet50.fc.in_features\n",
    "        for param in self.resnet50.parameters():\n",
    "            param.requires_grad = False\n",
    "        self.resnet50.fc = nn.Linear(in_features, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet50(x)\n",
    "        return x\n",
    "network = ResNet50(num_classes=5).cuda()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "    run  epoch       loss  accuracy  epoch duration  run duration    lr  \\\n0     1      1  16.193106     0.000        0.588532      0.589507  0.01   \n1     1      2  21.446534     0.200        0.607002      1.203508  0.01   \n2     1      3  25.043803     0.300        0.602352      1.810861  0.01   \n3     1      4  29.357632     0.200        0.688821      2.505681  0.01   \n4     1      5  31.431605     0.475        0.654049      3.164940  0.01   \n5     1      6  32.417106     0.675        0.721890      3.893404  0.01   \n6     1      7  34.831707     0.325        0.729268      4.629672  0.01   \n7     1      8  35.448148     0.825        0.615436      5.251131  0.01   \n8     1      9  36.261265     0.700        0.598593      5.855648  0.01   \n9     1     10  37.042073     0.750        0.598784      6.460489  0.01   \n10    1     11  37.350661     0.975        0.592046      7.059506  0.01   \n11    1     12  38.268474     0.600        0.695906      7.761484  0.01   \n12    1     13  38.421936     1.000        0.601103      8.370589  0.01   \n13    1     14  38.961275     0.700        0.732949      9.110493  0.01   \n14    1     15  39.137891     1.000        0.634822      9.754234  0.01   \n15    1     16  39.474379     0.925        0.610061     10.371482  0.01   \n16    1     17  39.610437     1.000        0.604986     10.982474  0.01   \n17    1     18  39.852216     1.000        0.674173     11.663647  0.01   \n18    1     19  39.976575     1.000        0.666236     12.336947  0.01   \n19    1     20  40.156401     1.000        0.674806     13.019835  0.01   \n20    1     21  40.275756     1.000        0.613400     13.640300  0.01   \n21    1     22  40.406353     1.000        0.762527     14.410623  0.01   \n22    1     23  40.525807     1.000        0.692188     15.111482  0.01   \n23    1     24  40.629980     1.000        0.609338     15.728827  0.01   \n24    1     25  40.740838     1.000        0.616209     16.353116  0.01   \n25    1     26  40.835169     1.000        0.635352     16.995592  0.01   \n26    1     27  40.929203     1.000        0.696865     17.701355  0.01   \n27    1     28  41.019727     1.000        0.623284     18.334672  0.01   \n28    1     29  41.102307     1.000        0.707135     19.049801  0.01   \n29    1     30  41.184535     1.000        0.701762     19.760562  0.01   \n30    1     31  41.261799     1.000        0.620722     20.390269  0.01   \n31    1     32  41.335097     1.000        0.709431     21.108419  0.01   \n32    1     33  41.406977     1.000        0.606702     21.725204  0.01   \n33    1     34  41.474990     1.000        0.605044     22.340269  0.01   \n34    1     35  41.540310     1.000        0.677629     23.026732  0.01   \n35    1     36  41.603824     1.000        0.661201     23.697055  0.01   \n36    1     37  41.664500     1.000        0.753865     24.463308  0.01   \n37    1     38  41.723031     1.000        0.707851     25.181192  0.01   \n38    1     39  41.779807     1.000        0.595475     25.787504  0.01   \n39    1     40  41.834405     1.000        0.695504     26.493916  0.01   \n40    1     41  41.887168     1.000        0.649439     27.153361  0.01   \n41    1     42  41.938362     1.000        0.739221     27.902586  0.01   \n42    1     43  41.987828     1.000        0.711151     28.625542  0.01   \n43    1     44  42.035710     1.000        0.722522     29.359060  0.01   \n44    1     45  42.082200     1.000        0.611288     29.982584  0.01   \n45    1     46  42.127268     1.000        0.631393     30.624199  0.01   \n46    1     47  42.170973     1.000        0.646771     31.281548  0.01   \n47    1     48  42.213447     1.000        0.658518     31.952928  0.01   \n48    1     49  42.254721     1.000        0.617003     32.582041  0.01   \n49    1     50  42.294822     1.000        0.677724     33.271859  0.01   \n\n    batch_size  shuffle  num_workers  \n0           40     True            2  \n1           40     True            2  \n2           40     True            2  \n3           40     True            2  \n4           40     True            2  \n5           40     True            2  \n6           40     True            2  \n7           40     True            2  \n8           40     True            2  \n9           40     True            2  \n10          40     True            2  \n11          40     True            2  \n12          40     True            2  \n13          40     True            2  \n14          40     True            2  \n15          40     True            2  \n16          40     True            2  \n17          40     True            2  \n18          40     True            2  \n19          40     True            2  \n20          40     True            2  \n21          40     True            2  \n22          40     True            2  \n23          40     True            2  \n24          40     True            2  \n25          40     True            2  \n26          40     True            2  \n27          40     True            2  \n28          40     True            2  \n29          40     True            2  \n30          40     True            2  \n31          40     True            2  \n32          40     True            2  \n33          40     True            2  \n34          40     True            2  \n35          40     True            2  \n36          40     True            2  \n37          40     True            2  \n38          40     True            2  \n39          40     True            2  \n40          40     True            2  \n41          40     True            2  \n42          40     True            2  \n43          40     True            2  \n44          40     True            2  \n45          40     True            2  \n46          40     True            2  \n47          40     True            2  \n48          40     True            2  \n49          40     True            2  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>run</th>\n      <th>epoch</th>\n      <th>loss</th>\n      <th>accuracy</th>\n      <th>epoch duration</th>\n      <th>run duration</th>\n      <th>lr</th>\n      <th>batch_size</th>\n      <th>shuffle</th>\n      <th>num_workers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>1</td>\n      <td>16.193106</td>\n      <td>0.000</td>\n      <td>0.588532</td>\n      <td>0.589507</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>2</td>\n      <td>21.446534</td>\n      <td>0.200</td>\n      <td>0.607002</td>\n      <td>1.203508</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>3</td>\n      <td>25.043803</td>\n      <td>0.300</td>\n      <td>0.602352</td>\n      <td>1.810861</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>4</td>\n      <td>29.357632</td>\n      <td>0.200</td>\n      <td>0.688821</td>\n      <td>2.505681</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>5</td>\n      <td>31.431605</td>\n      <td>0.475</td>\n      <td>0.654049</td>\n      <td>3.164940</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>1</td>\n      <td>6</td>\n      <td>32.417106</td>\n      <td>0.675</td>\n      <td>0.721890</td>\n      <td>3.893404</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>1</td>\n      <td>7</td>\n      <td>34.831707</td>\n      <td>0.325</td>\n      <td>0.729268</td>\n      <td>4.629672</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>1</td>\n      <td>8</td>\n      <td>35.448148</td>\n      <td>0.825</td>\n      <td>0.615436</td>\n      <td>5.251131</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>1</td>\n      <td>9</td>\n      <td>36.261265</td>\n      <td>0.700</td>\n      <td>0.598593</td>\n      <td>5.855648</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>1</td>\n      <td>10</td>\n      <td>37.042073</td>\n      <td>0.750</td>\n      <td>0.598784</td>\n      <td>6.460489</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>1</td>\n      <td>11</td>\n      <td>37.350661</td>\n      <td>0.975</td>\n      <td>0.592046</td>\n      <td>7.059506</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>1</td>\n      <td>12</td>\n      <td>38.268474</td>\n      <td>0.600</td>\n      <td>0.695906</td>\n      <td>7.761484</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>1</td>\n      <td>13</td>\n      <td>38.421936</td>\n      <td>1.000</td>\n      <td>0.601103</td>\n      <td>8.370589</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>1</td>\n      <td>14</td>\n      <td>38.961275</td>\n      <td>0.700</td>\n      <td>0.732949</td>\n      <td>9.110493</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>1</td>\n      <td>15</td>\n      <td>39.137891</td>\n      <td>1.000</td>\n      <td>0.634822</td>\n      <td>9.754234</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>1</td>\n      <td>16</td>\n      <td>39.474379</td>\n      <td>0.925</td>\n      <td>0.610061</td>\n      <td>10.371482</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>1</td>\n      <td>17</td>\n      <td>39.610437</td>\n      <td>1.000</td>\n      <td>0.604986</td>\n      <td>10.982474</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>1</td>\n      <td>18</td>\n      <td>39.852216</td>\n      <td>1.000</td>\n      <td>0.674173</td>\n      <td>11.663647</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>1</td>\n      <td>19</td>\n      <td>39.976575</td>\n      <td>1.000</td>\n      <td>0.666236</td>\n      <td>12.336947</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>1</td>\n      <td>20</td>\n      <td>40.156401</td>\n      <td>1.000</td>\n      <td>0.674806</td>\n      <td>13.019835</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>1</td>\n      <td>21</td>\n      <td>40.275756</td>\n      <td>1.000</td>\n      <td>0.613400</td>\n      <td>13.640300</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>1</td>\n      <td>22</td>\n      <td>40.406353</td>\n      <td>1.000</td>\n      <td>0.762527</td>\n      <td>14.410623</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>1</td>\n      <td>23</td>\n      <td>40.525807</td>\n      <td>1.000</td>\n      <td>0.692188</td>\n      <td>15.111482</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>1</td>\n      <td>24</td>\n      <td>40.629980</td>\n      <td>1.000</td>\n      <td>0.609338</td>\n      <td>15.728827</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>1</td>\n      <td>25</td>\n      <td>40.740838</td>\n      <td>1.000</td>\n      <td>0.616209</td>\n      <td>16.353116</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>25</th>\n      <td>1</td>\n      <td>26</td>\n      <td>40.835169</td>\n      <td>1.000</td>\n      <td>0.635352</td>\n      <td>16.995592</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>26</th>\n      <td>1</td>\n      <td>27</td>\n      <td>40.929203</td>\n      <td>1.000</td>\n      <td>0.696865</td>\n      <td>17.701355</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>27</th>\n      <td>1</td>\n      <td>28</td>\n      <td>41.019727</td>\n      <td>1.000</td>\n      <td>0.623284</td>\n      <td>18.334672</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>28</th>\n      <td>1</td>\n      <td>29</td>\n      <td>41.102307</td>\n      <td>1.000</td>\n      <td>0.707135</td>\n      <td>19.049801</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>29</th>\n      <td>1</td>\n      <td>30</td>\n      <td>41.184535</td>\n      <td>1.000</td>\n      <td>0.701762</td>\n      <td>19.760562</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>1</td>\n      <td>31</td>\n      <td>41.261799</td>\n      <td>1.000</td>\n      <td>0.620722</td>\n      <td>20.390269</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>1</td>\n      <td>32</td>\n      <td>41.335097</td>\n      <td>1.000</td>\n      <td>0.709431</td>\n      <td>21.108419</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>1</td>\n      <td>33</td>\n      <td>41.406977</td>\n      <td>1.000</td>\n      <td>0.606702</td>\n      <td>21.725204</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>1</td>\n      <td>34</td>\n      <td>41.474990</td>\n      <td>1.000</td>\n      <td>0.605044</td>\n      <td>22.340269</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>34</th>\n      <td>1</td>\n      <td>35</td>\n      <td>41.540310</td>\n      <td>1.000</td>\n      <td>0.677629</td>\n      <td>23.026732</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>1</td>\n      <td>36</td>\n      <td>41.603824</td>\n      <td>1.000</td>\n      <td>0.661201</td>\n      <td>23.697055</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>36</th>\n      <td>1</td>\n      <td>37</td>\n      <td>41.664500</td>\n      <td>1.000</td>\n      <td>0.753865</td>\n      <td>24.463308</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>37</th>\n      <td>1</td>\n      <td>38</td>\n      <td>41.723031</td>\n      <td>1.000</td>\n      <td>0.707851</td>\n      <td>25.181192</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>38</th>\n      <td>1</td>\n      <td>39</td>\n      <td>41.779807</td>\n      <td>1.000</td>\n      <td>0.595475</td>\n      <td>25.787504</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>39</th>\n      <td>1</td>\n      <td>40</td>\n      <td>41.834405</td>\n      <td>1.000</td>\n      <td>0.695504</td>\n      <td>26.493916</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>40</th>\n      <td>1</td>\n      <td>41</td>\n      <td>41.887168</td>\n      <td>1.000</td>\n      <td>0.649439</td>\n      <td>27.153361</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>1</td>\n      <td>42</td>\n      <td>41.938362</td>\n      <td>1.000</td>\n      <td>0.739221</td>\n      <td>27.902586</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>42</th>\n      <td>1</td>\n      <td>43</td>\n      <td>41.987828</td>\n      <td>1.000</td>\n      <td>0.711151</td>\n      <td>28.625542</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>43</th>\n      <td>1</td>\n      <td>44</td>\n      <td>42.035710</td>\n      <td>1.000</td>\n      <td>0.722522</td>\n      <td>29.359060</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>44</th>\n      <td>1</td>\n      <td>45</td>\n      <td>42.082200</td>\n      <td>1.000</td>\n      <td>0.611288</td>\n      <td>29.982584</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>45</th>\n      <td>1</td>\n      <td>46</td>\n      <td>42.127268</td>\n      <td>1.000</td>\n      <td>0.631393</td>\n      <td>30.624199</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>46</th>\n      <td>1</td>\n      <td>47</td>\n      <td>42.170973</td>\n      <td>1.000</td>\n      <td>0.646771</td>\n      <td>31.281548</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>1</td>\n      <td>48</td>\n      <td>42.213447</td>\n      <td>1.000</td>\n      <td>0.658518</td>\n      <td>31.952928</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>1</td>\n      <td>49</td>\n      <td>42.254721</td>\n      <td>1.000</td>\n      <td>0.617003</td>\n      <td>32.582041</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>49</th>\n      <td>1</td>\n      <td>50</td>\n      <td>42.294822</td>\n      <td>1.000</td>\n      <td>0.677724</td>\n      <td>33.271859</td>\n      <td>0.01</td>\n      <td>40</td>\n      <td>True</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = OrderedDict(\n",
    "    lr=[.01]\n",
    "    ,batch_size=[40]\n",
    "    ,shuffle=[True]\n",
    "    ,num_workers=[2]\n",
    ")\n",
    "m = RunManager()\n",
    "for run in RunBuilder().get_runs(params):\n",
    "\n",
    "    optimizer = optim.Adam(network.parameters(),lr=run.lr)\n",
    "\n",
    "    m.begin_run(run,network,train_dataloader)\n",
    "    for epoch in range(10):\n",
    "        m.begin_epoch()\n",
    "        for batch in train_dataloader:\n",
    "            img,lab = batch\n",
    "\n",
    "            preds = network(img.cuda())\n",
    "\n",
    "            loss = F.cross_entropy(preds, lab.cuda())\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            m.track_loss(loss)\n",
    "            m.track_num_correct(preds,lab.cuda())\n",
    "\n",
    "        m.end_epoch()\n",
    "    m.end_run()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 测试 #"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "在训练集上的精度为： 1.0\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for batch in test_dataloader:\n",
    "        img,lab = batch\n",
    "        img = img.cuda()\n",
    "        lab = lab.cuda()\n",
    "        preds = network(img)\n",
    "        correct += get_correct(preds,lab)\n",
    "print('在训练集上的精度为：',correct/len(test_datasets))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
